## 计数
帖子浏览数必须是实时或者近实时的，而不是每天或者每小时汇总
同一用户在短时间内多次访问帖子，只算一个浏览量
显示的浏览量与真实浏览量间允许有小百分之几的误差

简单实现：将访问用户的集合存储在内存的 hashMap 中，以帖子 Id 为 key
缺点：有的帖子有超过 100 万的独立访客，存储独立访客的 ID 并且频繁查询某个用户是否之前曾访问过会给内存和 CPU 造成很大的负担

基数估计：基于 HyperLogLog (以下简称 HLL )的计数法

## 异地多活
对于一个日活1000万的业务来说，每天注册用户可能是几万，修改用户信息的可能还不到1万，但登录用户是1000万，很明显我们应该保证登录的异地多活

## 缓存
读操作
尝试从缓存get数据，结果没有命中；
从数据库获取数据，读从库，读写分离；
把数据set到缓存，未来能够命中缓存

写操作
先操作数据库，再操作缓存
第一步成功，第二步失败，会导致，数据库里是新数据，而缓存里是旧数据，业务无法接受

先操作缓存（delete或者set），再操作数据库
使用set：第一步成功，第二步失败，会导致，缓存里是set后的数据，数据库里是之前的数据，数据不一致，业务无法接受
使用delete：第一步成功，第二步失败，会导致，缓存里没有数据，数据库里是之前的数据，数据没有不一致，对业务无影响。只是下一次读取，会多一次cache miss


缓存更新
客户端从缓存中根据KEY读取数据，如果读到了数据则流程结束，如果没有读到数据（可能会有多个并发都没有读到数据），这时候使用缓存系统中的setNX方法设置一个值（这种方法类似加个锁），没有设置成功的请求则sleep一段时间，设置成功的请求读取数据库获取值，如果获取到则更新缓存，流程结束，之前sleep的请求这时候唤醒后直接再从缓存中读取数据，此时流程结束。如果数据库中没有我们需要的数据，则往缓存中插入一个NULL字符串


缓存穿透
1. 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试
2. 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作，会有一致性问题
3. 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回

缓存雪崩
1. 给缓存的失效时间，加上一个随机值，避免集体失效
2. 使用互斥锁，但是该方案吞吐量明显下降


短链接原理
1. 输入 http://t.cn/RlB2PdD
2. DNS首先解析获得 http://t.cn 的 IP 地址
3. DNS 获得 IP 地址以后，会向这个地址发送 HTTP GET 请求，查询短码 RlB2PdD
4. http://t.cn 服务器会通过短码 RlB2PdD 获取对应的长 URL
5. 请求通过 HTTP 301 转到对应的长 URL



### 线程池设计
如果是CPU密集型应用，则线程池大小设置为N+1
如果是IO密集型应用，则线程池大小设置为2N+1

最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目

多线程适用场景一般是：存在相当比例的IO和网络操作




### 乐观锁
```
int version = executeSql("select version from... where id = $id");
```
```
boolean succ = executeSql("update ... where id = $id and version = $version");
```
乐观锁在同一时刻，只有一个更新请求会成功，其他的更新请求会失败，因此，适用于并发不高的场景

### 悲观锁
```
executeSql("select ... where id = $id for update");
```

### 行级锁
通常在扣减库存的场景下使用行级锁，这样可以通过数据库引擎本身对记录加锁的控制，保证数据库更新的安全性，并且通过 where 语句的条件，保证库存不会被减到0以下，也就是能够有效的控制超卖的场景
```
boolean result = executeSql("update ... set amount = amount - 1 where id = $id and amount > 1");
if (result) {
    // process sucessful logic
} else {
    // process failure logic
}
```

状态转换的时候使用行级锁，状态只能从一种状态转换到另外一种状态
```
boolean result = executeSql("update ... set status = 'doing' where id = $id and status = 'init'");

if (result) {
    // process sucessful logic
} else {
    // process failure logic
}
```


### feed
拉模式|读扩散
关注列表
粉丝列表
feed 列表：记录曾经发布的所有feed数据

发布 feed：向相应的队列中加入一条 feed
取关：分别从关注列表与粉丝列表中删除对应的用户
获取 feed：先获取用户的关注列表，然后获取关注列表中每个用户发布的 feed，最后对取出的消息进行排序

优点
1. 存储结构简单，数据存储量较小，关系数据与feed数据都只存一份
2. 取消关注，发布feed的业务流程非常简单
3. 适合项目早期用户量、数据量、并发量不大时的快速实现

推模式|写扩散
关注列表
粉丝列表
feed 列表：与拉（读扩散）不同，除了记录自己曾经发布的所有feed数据，还需要记录收到的feed数据

关注：在粉丝列表与关注列表中添加对应用户，在关注者的 feed 列表中加入被关注者发布的 feed 数据
取关：分别从关注列表与粉丝列表中删除对应的用户，在关注者的 feed 列表中删除被关注者发布的 feed 数据
获取 feed：直接从 feed 列表中取最新 feed 数据
发布 feed：先将该 feed 加入发布者的 feed 列表中，然后获取发布者的粉丝列表，先粉丝的 feed 列表中加入该 feed 数据

优点
1. 消除了拉模式的 IO 集中点，每个用户都读取自己的数据，高并发下锁竞争少
2. 拉取 feed 流的业务流程简单
3. 拉取 feed 流不需要进行大量内存计算，性能很高

缺点
1. 消耗存储资源，feed 数据会存储很多份
2. 关注、取关、发布 feed 的业务流程复杂


使用Redis的zset结构做存储，天然有序，支持原子的增/删/查询操作

插入一条feed_id为88888888的Feed，插入时间为1460198781
ZADD timeline 1460198781 88888888

查看最近的100条Feed
ZREVRANGE timeline 0 100

redis对小zset采用ziplist的方式紧凑存储，列表增长会转换为skiplist，内存利用率下降

通过timeline聚合层，根据用户的好友关系和个人Feed列表，找到上次访问之后产生的新Feed，增量实时聚合新内容
1. 遍历我的好友，找到最近发表过Feed的人
2. 遍历最近发表过Feed的人，得到id和time
3. 合并到我的timeline

对于中小型的Feed系统，feed数据可以通过同步push模式进行分发。用户每发表一条feed，后端系统根据用户的粉丝列表进行全量推送，粉丝用户通过自己的inbox来查看所有最新的feed。

将同步push模式改成了异步hybrid模式，即pull+push模式。用户发表feed后首先写入消息队列，由队列处理机进行异步更新，更新时不再push到所有粉丝的inbox，而是存放到发表者自己的outbox；用户查看时，通过pull模式对关注人的outbox进行实时聚合获取。基于性能方面的考虑，部分个性化数据仍然先push到目标用户的inbox。用户访问时，系统将用户自己的inbox和TA所有的关注人outbox一起进行聚合，最终得到Feed列表

整个Feed流构建过程中， Feed系统主要进行了如下操作：
根据用户uid获取关注列表；
根据关注列表获取每一个被关注者的最新微博ID 列表；
获取用户自己收到的微博 ID 列表（即 inbox）；
对这些 ID 列表进行合并、排序及分页处理后，拿到需要展现的微博 ID 列表；
根据这些 ID 获取对应的微博内容；
对于转发feed进一步获取源feed的内容；
获取用户设置的过滤条件进行过滤
获取feed/源feed作者的 user 信息并进行组装；
获取请求者对这些feed是否收藏、是否赞等进行组装；
获取这些feed的转发、评论、赞等计数等进行组装；
组装完毕，转换成标准格式返回给请求方

一个典型的Feed系统的缓存设计主要分为INBOX、OUTBOX、SOCIAL GRAPH、CONTENT、EXISTENCE、CONTENT共六部分

Feed id存放在INBOX cache和OUTBOX cache中，存放格式是vector（即有序数组）

INBOX 缓存层用于存放聚合效率低的feed id（类似定向微博directed feed）。当用户发表只展现给特定粉丝、特定成员组织的feed时，Feed系统会首先拿到待推送（push）的用户列表，然后将这个feed id推送（push）给对应粉丝的INBOX。因此INBOX是以访问者UID来构建key的，其更新方式是先gets并本地，变更后再cas到异地Memcached缓存

OUTBOX 缓存层用于直接缓存用户发表的普通类型feed id，这个cache以发表者UID来构建key。其中outbox又主要分为vectorcache和archive data cache；vectorcache用于缓存最新发表的feed id、commentid等，按具体业务类型分池放置。如果用户最近没有发表新feed，vector cache为空，就要获取archive data里的feed id。

SOCIAL GRAPH缓存层主要包括用户的关注关系及用户的user信息。用户的关注关系主要包括用户的关注（following）列表、粉丝（follower）列表、双向列表等。

CONTENT 缓存层主要包括热门feed的content、全量feed的content。热门feed是指热点事件爆发时，引发热点事件的源feed。由于热门feed被访问的频率远大于普通feed，比如微博中单条热门feed的QPS可能达到数十万的级别，所以热门feed需要独立缓存，并缓存多份，以提高缓存的访问性能。

EXISTENCE 缓存层主要用于缓存各种存在性判断的业务，诸如是否已赞（liked）、是否已阅读（readed）这类需求。

COUNTER缓存用于缓存各种计数。Feed系统中计数众多，如用户的feed发表数、关注数、粉丝数，单条feed的评论数、转发数、赞数及阅读数，话题相关计数等。




网页端消息接受
轮询拉取
1. 发送方发送了消息，先入队列
2. 网页端定时器每隔一段时间发起一个轮询请求，拉取队列里的消息
3. 如果队列里有消息，就返回消息
4. 如果队列里无消息，就10秒后再次轮询

优点：实现简单，直观且，容易理解
缺点：实时性差，最坏的情况下，1条消息进入队列后，10s之后才会收到；效率低下，发消息是一个低频动作，如果10次轮询才收到1条消息，请求有效性只有10%，浪费了大量服务器资源

长连接

HTTP 长轮询
浏览器与服务端之间建立了一条通知连接，只用来收取推送通知，不像普通的请求-响应式HTTP请求，该通知连接会被服务端夯住，直到有推送通知到达，或者超过约定的时间
1. 发起通知连接时，队列里正好有消息，则：
发起通知连接，正好队列里有消息
实时把队列里的消息带回
立马再发起通知连接
2. 发起通知连接时，队列里无消息，则：
发起通知连接时，队列里无消息
一直等待，直到触发时间阈值，返回无消息
立马再发起通知连接
3. 新消息来时，正好有通知连接在，则：
通知连接实时将消息带回
立马再发起通知连接
4. 新消息来时，没有通知连接，则：
把新消息放入队列


群消息发送
群消息表：记录群消息
group_msgs(msgid, gid, sender_uid, time, content);
各字段的含义为：消息ID，群ID，发送方UID，发送时间，发送内容

群成员表：记录群里的成员，以及每个成员收到的最后一条群消息
group_users(gid, uid, last_ack_msgid);
各字段的含义为：群ID，群成员UID，群成员最后收到的一条群消息ID

消息回执表：用来记录消息的已读回执
msg_acks(sender_uid, msgid, recv_uid, gid, if_ack);
各字段的含义为：发送方UID，消息ID，回执方UID，群ID，回执标记



session 一致性问题
1. session同步法
多个web-server之间相互同步session，这样每个web-server之间都包含全部的session
优点：
web-server支持的功能，应用程序不需要修改代码
不足：
session的同步需要数据传输，占内网带宽，有时延
所有web-server都包含所有session数据，数据量受内存限制，无法水平扩展
2. 客户端存储法
优点：服务端不需要存储
缺点：
每次http请求都携带session，占外网带宽
数据存储在端上，并在网络传输，存在泄漏、篡改、窃取等安全隐患
session存储的数据大小受cookie限制
3. 反向代理hash一致性
反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个web-server上，这样同一个用户的请求就落在同一台web-server上

优点：
只需要改nginx配置，不需要修改应用代码
负载均衡，只要hash属性是均匀的，多台web-server的负载是均衡的
可以支持web-server水平扩展（session同步法是不行的，受内存限制）

不足：
如果web-server重启，一部分session会丢失，产生业务影响，例如部分用户重新登录
如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session

4. 后端统一存储
优点：
没有安全隐患
可以水平扩展，数据库/缓存水平切分即可
web-server重启或者扩容都不会有session丢失

不足：增加了一次网络调用，并且需要修改应用代码


RAID0
将连续的数据分散到不同的磁盘上存储，这些不同的磁盘能同时并行存取数据

RAID1
将数据完全复制到另一个磁盘上，磁盘空间利用率只有50%

RAID0+1

RAID5


消息系统设计
消息分类
公告 Announce
提醒 Remind
私信 Message

点赞，关注
CommentEventHandler
LoginEventHandler
LikeEventHandler
VoteEventHandler
sechma(id, type, actorId, entityType, entityId, entityOwnerId, createdTime);

提醒：小明喜欢了文章
entityId：文章 id
entityType：类型是文章
actorId：小明

用户消息队列：遍历订阅表、拉取公告和提醒时创建，新建信息后立刻创建
```
id
isRead
user：用户消息所属者
notify：关联的 Notify
createdAt
```

订阅
```
target：目标的ID
targetType：目标的类型
action：订阅动作，如: comment/like/post/update
user
createdAt
```
小明关注了产品A的评论
arget: 产品 A 的 ID
targetType: 'product'
action: 'comment'
user: 小明的 ID

createAnnounce(content, sender)：往Notify表中插入一条公告记录
createRemind(target, targetType, action, sender, content)：往Notify表中插入一条提醒记录
createMessage(content, sender, receiver)：往Notify表中插入一条信息记录；往UserNotify表中插入一条记录，并关联新建的Notify

pullAnnounce(user)
从UserNotify中获取最近的一条公告信息的创建时间: lastTime
用lastTime作为过滤条件，查询Notify的公告信息
新建UserNotify并关联查询出来的公告信息

pullRemind(user)
查询用户的订阅表，得到用户的一系列订阅记录
通过每一条的订阅记录的target、targetType、action、createdAt去查询Notify表，获取订阅的Notify记录。（注意订阅时间必须早于提醒创建时间）
查询用户的配置文件SubscriptionConfig，如果没有则使用默认的配置DefaultSubscriptionConfig
使用订阅配置，过滤查询出来的Notify
使用过滤好的Notify作为关联新建UserNotify

subscribe(user, target, targetType, reason)
通过reason，查询NotifyConfig，获取对应的动作组:actions
遍历动作组，每一个动作新建一则Subscription记录

cancelSubscription(user, target ,targetType)
删除user、target、targetType对应的一则或多则记录

getSubscriptionConfig(userID)
查询SubscriptionConfig表，获取用户的订阅配置

updateSubscriptionConfig(userID)
更新用户的SubscriptionConfig记录

getUserNotify(userID)
获取用户的消息列表

read(user, notifyIDs)
更新指定的notify，把isRead属性设置为true


日志分类
info.log：业务关键步骤信息。
error.log：业务发生的错误以及堆栈信息。
sql_info.log：超过10ms的SQL调用。
api_info.log：api调用的关键信息。
rpc_info.log：rpc调用的信息

日志信息（api_info.log、rpc_info.log）
请求参数
traceId，日志追踪使用的唯一ID
请求客户端IP（rpc日志中记录目标服务端IP端口）
响应参数
处理耗时

traceId 的作用是把分散在各个日志文件中的日志信息都串起来，即一个请求产生的所有日志都有同一个唯一的 traceId，这样在ELK中查询日志时，把 traceId 作为查询条件一步就把这次请求的所有日志都查出来。同时 traceId 作为响应参数之一，便于系统间排查问题
在 Controller 的 AOP 中使用 slf4j MDC 把 traceId 放到线程上下文，对业务编码无入侵。traceId 的生成策略，可以有很多选择，只要在当天的日志索引中唯一即可，并没有太强的要求，账户团队最后使用的是毫秒时间戳 + 幂等ID + 6位随机数

从输入URL到页面加载
1. DNS解析(浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存)
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束








