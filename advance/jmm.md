## jvm 内存结构
### 虚拟机栈
Java 虚拟机栈是线程私有的内存空间，它和 Java 线程一起创建

当创建一个线程时，会在虚拟机栈中申请一个线程栈，用来保存方法的局部变量、操作数栈、动态链接方法和返回地址等信息，并参与方法的调用和返回。每一个方法的调用都伴随着栈帧的入栈操作，方法的返回则是栈帧的出栈操作

如果是原生数据类型的局部变量，那么它的内容就全部保留在线程栈上
如果是对象引用，则栈中的局部变量槽位中保存着对象的引用地址，而实际的对象内容保存在堆中
对象的成员变量与对象本身一起存储在堆上，不管成员变量的类型是原生数值，还是对象引用
类的静态变量则和类定义一样都保存在堆中

### 本地方法栈
本地方法栈与虚拟机栈非常相似，区别仅仅是虚拟机栈为虚拟机执行 Java 方法，而本地方法栈则是 Native 方法服务

### 堆
堆内存是 JVM 中最大的一块，被所有线程共享。几乎所有的对象实例都在这里分配内存

堆被划分为新生代和老年代，新生代又被进一步划分为 Eden 和 Survivor 区，最后 Survivor 由 From Survivor 和 To Survivor 组成

在 Java6 版本中，永久代在非堆内存区；到了 Java7 版本，永久代的静态变量和运行时常量池被合并到了堆中；而到了 Java8，永久代被元空间取代了

### 程序计数器
程序计数器是一块很小的内存空间，主要用来记录各个线程执行的字节码的地址，例如，分支、循环、跳转、异常、线程恢复等都依赖于计数器

如果一个线程的时间片用完了，或者是其它原因导致这个线程的 CPU 资源被提前抢夺，那么这个退出的线程就需要单独的一个程序计数器，来记录下一条运行的指令

### 方法区
方法区主要是用来存放已被虚拟机加载的类相关信息，包括类信息、运行时常量池、字符串常量池。类信息又包括了类的版本、字段、方法、接口和父类等信息

方法区与堆空间类似，也是一个共享内存区，所以方法区是线程共享的。假如两个线程都试图访问方法区中的同一个类信息，而这个类还没有装入 JVM，那么此时就只允许一个线程去加载它，另一个线程必须等待

在 HotSpot 虚拟机 Java7 版本中已经将永久代的静态变量和运行时常量池转移到了堆中，其余部分则存储在 JVM 的非堆内存中

Java8 版本将方法区中实现的永久代去掉，用元空间代替了之前的永久代，并且元空间的存储位置是本地内存。之前永久代的类的元数据存储在了元空间，永久代的静态变量以及运行时常量池则跟 Java7 一样，转移到了堆中


## 栈内存结构
每启动一个线程，JVM 就会在栈空间栈分配对应的线程栈，比如 1MB 的空间（‐Xss1m）。线程栈也叫做 Java 方法栈，如果使用了 JNI 方法，则会分配一个单独的本地方法栈

线程执行过程中，一般会有多个方法组成调用栈，每执行到一个方法，就会创建对应的栈帧

栈帧是一个逻辑上的概念，具体的大小在一个方法编写完成后基本上就能确定。比如返回值、局部变量、操作数栈，以及 class 指针（标识这个栈帧对应的是哪个类的方法，指向非堆里面的 Class 对象）


## 堆内存结构
JVM 将逻辑上的 Java 堆划分为堆和非堆两个部分。这是因为我们编码时基本上只能使用堆这部分空间，发生内存分配和回收的主要区域也在这部分

JVM 将堆内存分为年轻代和老年代两部分。年轻代还划分为 3 个内存池，新生代和存活区，在大部分 GC 算法中有 2 个存活区（S0，S1），在任何时刻，S0 和 S1 总有一个是空的，但一般较小，不会浪费多少空间

具体实现对新生代还有优化，那就是 TLAB（Thread Local Allocation Buffer），给每个线程先划定一小片空间，你创建的对象先在这里分配，满了再换。这能极大降低并发资源锁定的开销

非堆本质上还是堆，只是一般不归 GC 管理，里面划分为 3 个内存池：
1. Metaspace，以前叫持久代（永久代，Permanent generation），Java8 开始叫 Metaspace，Java8 将方法区移动到了 Meta 区里面
2. CCS，Compressed Class Space，存放 class 信息的，和 Metaspace 有交叉
3. Code Cache，存放 JIT 编译器编译后的本地机器代码


## JMM 与线程规范
给定一个程序和该程序的一串执行轨迹，内存模型描述了该执行轨迹是否是该程序的一次合法执行。内存模型检查执行轨迹中的每次读操作，然后根据特定规则，检验该读操作观察到的写是否合法

### 内存屏障
内存屏障可分为读屏障和写屏障，用于控制可见性。常见的内存屏障包括：
1. LoadLoad
2. StoreStore
3. LoadStore
4. StoreLoad

这些屏障的主要目的，是用来短暂屏蔽 CPU 的指令重排序功能。和 CPU 约定好，看见这些指令时，就要保证这个指令前后的相应操作不会被打乱。例如：
1. LoadLoad 表示屏障前面的 Load 指令一定要先执行完，才能执行屏障后面的 Load 指令
2. StoreLoad 能确保屏障之前执行的所有 store 操作都对其他处理器可见，在屏障后面执行的 load 指令，都能取得到最新的值

代价最高的是 StoreLoad 屏障，它同时具有其他几类屏障的效果，可以用来代替另外三种内存屏障。就是只要有一个 CPU 内核收到这类指令，就会做一些操作，同时发出一条广播，给某个内存地址打个标记，其他 CPU 内核与自己的缓存交互时，就知道这个缓存不是最新的，需要从主内存重新进行加载处理