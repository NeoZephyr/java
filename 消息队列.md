RabbitMQ 在这个基本概念之上, 多做了一层抽象, 在发消息者和队列之间, 加入了交换器 (Exchange). 这样发消息者和队列就没有直接联系, 转而变成发消息者把消息给交换器, 交换器根据调度策略再把消息再给队列

虚拟主机：一个虚拟主机持有一组交换机、队列和绑定

RabbitMQ当中，用户只能在虚拟主机的粒度进行权限控制。因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创建一个虚拟主机。每一个RabbitMQ服务器都有一个默认的虚拟主机“/”

交换机：Exchange 用于转发消息，但是它不会做存储 ，如果没有 Queue bind 到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息
路由键：消息到交换机的时候，交互机会转发到对应的队列中，那么究竟转发到哪个队列，就要根据该路由键
绑定：也就是交换机需要和队列相绑定

交换机(Exchange)
交换机有四种类型：Direct, topic, Headers and Fanout

Direct Exchange
Direct Exchange是RabbitMQ默认的交换机模式，也是最简单的模式，根据key全文匹配去寻找队列
X - Q1 binding key orange
X - Q2 binding key black 和 green

Topic Exchange
转发消息主要是根据通配符。在这种交换机下，队列和交换机的绑定会定义一种路由模式。那么，通配符就要在这种路由模式和路由键之间匹配后交换机才能转发消息

Headers Exchange

Fanout Exchange
消息广播的模式，不管路由键或者是路由模式，会把消息发给绑定给它的全部队列，如果配置了routing_key会被忽略

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```
```
spring.application.name=spirng-boot-rabbitmq

spring.rabbitmq.host=192.168.0.86
spring.rabbitmq.port=5672
spring.rabbitmq.username=admin
spring.rabbitmq.password=123456
```

```
@Configuration
public class RabbitConfig {    
    @Bean
    public Queue Queue() {        
        return new Queue("hello");
    }
}
```
```
public class HelloSender {    
    @Autowired
    private AmqpTemplate rabbitTemplate;    
    
    public void send() {
        String context = "hello " + new Date();
        System.out.println("Sender : " + context);        
        this.rabbitTemplate.convertAndSend("hello", context);
    }
}
```
```
@Component
@RabbitListener(queues = "hello")
public class HelloReceiver {    
    @RabbitHandler
    public void process(String hello) {
        System.out.println("Receiver  : " + hello);
    }
}
```
```
@RunWith(SpringRunner.class)
@SpringBootTest
public class RabbitMqHelloTest {    
    @Autowired
    private HelloSender helloSender;    
   
    @Test
    public void hello() throws Exception {
        helloSender.send();
    }
}
```

对象发送的支持
```
public void send(User user) {
    System.out.println("Sender object: " + user.toString());    
    this.rabbitTemplate.convertAndSend("object", user);
}
```
```
@RabbitHandler
public void process(User user) {
    System.out.println("Receiver object : " + user);
}
```

Topic Exchange
```
@Configuration
public class TopicRabbitConfig {    
    final static String message = "topic.message";
    final static String messages = "topic.messages";

    @Bean
    public Queue queueMessage() {        
       return new Queue(TopicRabbitConfig.message);
    }    
    @Bean
    public Queue queueMessages() {        
       return new Queue(TopicRabbitConfig.messages);
    }    
    @Bean
    TopicExchange exchange() {        
       return new TopicExchange("exchange");
    }    
    @Bean
    Binding bindingExchangeMessage(Queue queueMessage, TopicExchange exchange) {        
       return BindingBuilder.bind(queueMessage)
       .to(exchange).with("topic.message");
    }    
    @Bean
    Binding bindingExchangeMessages(Queue queueMessages, TopicExchange exchange) {        
       return BindingBuilder.bind(queueMessages)
       .to(exchange).with("topic.#");
    }
}
```
```
public void send1() {
    String context = "hi, i am message 1";
    System.out.println("Sender : " + context);    
    this.rabbitTemplate.convertAndSend("exchange", "topic.message", context);
}

public void send2() {
    String context = "hi, i am messages 2";
    System.out.println("Sender : " + context);    
    this.rabbitTemplate.convertAndSend("exchange", "topic.messages", context);
}
```

Fanout Exchange
```
@Configuration
public class FanoutRabbitConfig {    

    @Bean
    public Queue AMessage() {        
       return new Queue("fanout.A");
    }    
    @Bean
    public Queue BMessage() {        
        return new Queue("fanout.B");
    }    
    @Bean
    public Queue CMessage() {        
         return new Queue("fanout.C");
    }    
    @Bean
    FanoutExchange fanoutExchange() {
         return new FanoutExchange("fanoutExchange");
    }    
    @Bean
    Binding bindingExchangeA(Queue AMessage,FanoutExchange fanoutExchange) {        
         return BindingBuilder.bind(AMessage).to(fanoutExchange);
    }    
    @Bean
    Binding bindingExchangeB(Queue BMessage, FanoutExchange fanoutExchange) {        
         return BindingBuilder.bind(BMessage).to(fanoutExchange);
    }    
    @Bean
    Binding bindingExchangeC(Queue CMessage, FanoutExchange fanoutExchange) {        
         return BindingBuilder.bind(CMessage).to(fanoutExchange);
    }

}
```
```
public void send() {
        String context = "hi, fanout msg ";
        System.out.println("Sender : " + context);       
        this.rabbitTemplate.convertAndSend("fanoutExchange","", context);
}
```

消息队列选择要点：
Kafka（1.1.0版本）不支持，RabbitMQ（3.6.10版本）支持。建议优先级大小设置在0-10之间。
优先级队列：如果消费者的消费速度大于生产者的速度，并且消息中间件服务器（一般简单的称之为Broker）中没有消息堆积，那么对于发送的消息设置优先级也就没有什么实质性的意义

延迟队列（三十分钟之内未付款，订单自动取消）
Kafka（1.1.0版本）不支持，RabbitMQ（3.6.10版本）支持
基于消息的延迟：指为每条消息设置不同的延迟时间，那么每当队列中有新消息进入的时候就会重新根据延迟时间排序，当然这也会对性能造成极大的影响
基于队列的延迟：实际应用中大多采用基于队列的延迟，设置不同延迟级别的队列，比如5s、10s、30s、1min、5mins、10mins等，每个队列中消息的延迟时间都是相同的，这样免去了延迟排序所要承受的性能之苦，通过一定的扫描策略（比如定时）即可投递超时的消息

死信队列
Kafka（1.1.0版本）不支持，RabbitMQ（3.6.10版本）支持
由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列

回退队列
如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认（Ack）,进而发生回滚消息的操作之后消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常的处理提供的一种机制保障。实际情况下，回退队列的角色可以由死信队列和重试队列来扮演

重试队列
Kafka（1.1.0版本）不支持，RabbitMQ（3.6.10版本）不支持。RabbitMQ中可以参考延迟队列实现一个重试队列，二次封装比较简单。如果要在Kafka中实现重试队列，首先得实现延迟队列的功能，相对比较复杂。
重试队列其实可以看成是一种回退队列，具体指消费端消费消息失败时，为防止消息无故丢失而重新将消息回滚到Broker中。与回退队列不同的是重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。举个例子：消息第一次消费失败入重试队列Q1，Q1的重新投递延迟为5s，在5s过后重新投递该消息；如果消息再次消费失败则入重试队列Q2，Q2的重新投递延迟为10s，在10s过后再次投递该消息。以此类推，重试越多次重新投递的时间就越久，为此需要设置一个上限，超过投递次数就入死信队列。重试队列与延迟队列有相同的地方，都是需要设置延迟级别，它们彼此的区别是：延迟队列动作由内部触发，重试队列动作由外部消费端触发；延迟队列作用一次，而重试队列的作用范围会向后传递

消费模式
Kafka（1.1.0版本）拉模式，RabbitMQ（3.6.10版本）推模式+拉模式
消费模式分为推（push）模式和拉（pull）模式。推模式是指由Broker主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。而拉模式是指消费端主动向Broker端请求拉取（一般是定时或者定量）消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量

广播消费
Kafka（1.1.0版本）支持。Kafka对于广播消费的支持相对而言更加正统。RabbitMQ（3.6.10版本）支持，但力度较Kafka弱。
消息一般有两种传递模式：
点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。对于点对点的模式而言，消息被消费以后，队列中不会再存储，所以消息消费者不可能消费到已经被消费的消息。虽然队列可以支持多个消费者，但是一条消息只会被一个消费者消费。
发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（topic），主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者则从主题中订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。RabbitMQ是一种典型的点对点模式，而Kafka是一种典型的发布订阅模式。但是RabbitMQ中可以通过设置交换器类型来实现发布订阅模式而达到广播消费的效果，Kafka中也能以点对点的形式消费，你完全可以把其消费组（consumer group）的概念看成是队列的概念。不过对比来说，Kafka中因为有了消息回溯功能的存在，对于广播消费的力度支持比RabbitMQ的要强。

消息回溯
Kafka（1.1.0版本）支持。Kafka支持按照offset和timestamp两种维度进行消息回溯。RabbitMQ（3.6.10版本）不支持。RabbitMQ中消息一旦被确认消费就会被标记删除。
一般消息在消费完成之后就被处理了，之后再也不能消费到该条消息。消息回溯正好相反，是指消息在消费完成之后，还能消费到之前被消费掉的消息。对于消息而言，经常面临的问题是“消息丢失”，至于是真正由于消息中间件的缺陷丢失还是由于使用方的误用而丢失一般很难追查，如果消息中间件本身具备消息回溯功能的话，可以通过回溯消费复现“丢失的”消息进而查出问题的源头之所在。消息回溯的作用远不止与此，比如还有索引恢复、本地缓存重建，有些业务补偿方案也可以采用回溯的方式来实现

https://www.confluent.io/blog/publishing-apache-kafka-new-york-times/
消息堆积+持久化
Kafka（1.1.0版本）支持。RabbitMQ（3.6.10版本）支持。一般情况下，内存堆积达到特定阈值时会影响其性能，但这不是绝对的。如果考虑到吞吐这因素，Kafka的堆积效率比RabbitMQ总体上要高很多。
流量削峰是消息中间件的一个非常重要的功能，而这个功能其实得益于其消息堆积能力。从某种意义上来讲，如果一个消息中间件不具备消息堆积的能力，那么就不能把它看做是一个合格的消息中间件。消息堆积分内存式堆积和磁盘式堆积。
RabbitMQ是典型的内存式堆积，但这并非绝对，在某些条件触发后会有换页动作来将内存中的消息换页到磁盘（换页动作会影响吞吐），或者直接使用惰性队列来将消息直接持久化至磁盘中。
Kafka是一种典型的磁盘式堆积，所有的消息都存储在磁盘中。一般来说，磁盘的容量会比内存的容量要大得多，对于磁盘式的堆积其堆积能力就是整个磁盘的大小。从另外一个角度讲，消息堆积也为消息中间件提供了冗余存储的功能

消息追踪
Kafka不支持。消息追踪可以通过外部系统来支持，但是支持粒度没有内置的细腻。RabbitMQ（3.6.10版本）支持。RabbitMQ中可以采用Firehose或者rabbitmq_tracing插件实现。不过开启rabbitmq_tracing插件件会大幅影响性能，不建议生产环境开启，反倒是可以使用Firehose与外部链路系统结合提供高细腻度的消息追踪支持。
对于消息追踪最通俗的理解就是要知道消息从哪来，存在哪里以及发往哪里去。基于此功能下，我们可以对发送或者消费完的消息进行链路追踪服务，进而可以进行问题的快速定位与排查

消息过滤
Kafka 客户端级别的支持。RabbitMQ 不支持。但是二次封装一下也非常简单。
消息过滤是指按照既定的过滤规则为下游用户提供指定类别的消息
kafka而言，完全可以将不同类别的消息发送至不同的topic中，由此可以实现某种意义的消息过滤，或者Kafka还可以根据分区对同一个topic中的消息进行分类。不过更加严格意义上的消息过滤应该是对既定的消息采取一定的方式按照一定的过滤规则进行过滤。同样以Kafka为例，可以通过客户端提供的ConsumerInterceptor接口或者Kafka Stream的filter功能进行消息过滤

多租户
Kafka 不支持，RabbitMQ 支持
也可以称为多重租赁技术，是一种软件架构技术，主要用来实现多用户的环境下公用相同的系统或程序组件，并且仍可以确保各用户间数据的隔离性
RabbitMQ就能够支持多租户技术，每一个租户表示为一个vhost，其本质上是一个独立的小型RabbitMQ服务器，又有自己独立的队列、交换器及绑定关系等，并且它拥有自己独立的权限。vhost就像是物理机中的虚拟机一样，它们在各个实例间提供逻辑上的分离，为不同程序安全保密地允许数据，它既能将同一个RabbitMQ中的众多客户区分开，又可以避免队列和交换器等命名冲突

多协议支持
Kafka 只支持定义协议，目前几个主流版本间存在兼容性问题。RabbitMQ本身就是AMQP协议的实现，同时支持MQTT、STOMP等协议。
消息是信息的载体，为了让生产者和消费者都能理解所承载的信息（生产者需要知道如何构造消息，消费者需要知道如何解析消息），它们就需要按照一种统一的格式描述消息，这种统一的格式称之为消息协议。有效的消息一定具有某种格式，而没有格式的消息是没有意义的。一般消息层面的协议有AMQP、MQTT、STOMP、XMPP等（消息领域中的JMS更多的是一个规范而不是一个协议），支持的协议越多其应用范围就会越广，通用性越强，比如RabbitMQ能够支持MQTT协议就让其在物联网应用中获得一席之地。还有的消息中间件是基于其本身的私有协议运转的，典型的如Kafka

流量控制
Kafka 支持client和user级别，通过主动设置可将流控作用于生产者或消费者。RabbitMQ的流控基于Credit-Based算法，是内部被动触发的保护机制，作用于生产者层面。
流量控制（flow control）针对的是发送方和接收方速度不匹配的问题，提供一种速度匹配服务抑制发送速率使接收方应用程序的读取速率与之相适应。通常的流控方法有Stop-and-wait、滑动窗口以及令牌桶等

消息顺序性
Kafka 支持单分区（partition）级别的顺序性。RabbitMQ 顺序性的条件比较苛刻，需要单线程发送、单线程消费并且不采用延迟队列、优先级队列等一些高级功能，从某种意义上来说不算支持顺序性。
顾名思义，消息顺序性是指保证消息有序。这个功能有个很常见的应用场景就是CDC（Change Data Chapture），以MySQL为例，如果其传输的binlog的顺序出错，比如原本是先对一条数据加1，然后再乘以2，发送错序之后就变成了先乘以2后加1了，造成了数据不一致

安全机制
Kafka （TLS/SSL、SASL）身份认证和（读写）权限控制。RabbitMQ 与 kafka 类似
在Kafka 0.9版本之后就开始增加了身份认证和权限控制两种安全机制。身份认证是指客户端与服务端连接进行身份认证，包括客户端与Broker之间、Broker与Broker之间、Broker与ZooKeeper之间的连接认证，目前支持SSL、SASL等认证机制。权限控制是指对客户端的读写操作进行权限控制，包括对消息或Kafka集群操作权限控制。权限控制是可插拔的，并支持与外部的授权服务进行集成。对于RabbitMQ而言，其同样提供身份认证（TLS/SSL、SASL）和权限控制（读写操作）的安全机制

消息幂等性
Kafka 支持单个生产者单分区单会话的幂等性。RabbitMQ 不支持
对于确保消息在生产者和消费者之间进行传输而言一般有三种传输保障（delivery guarantee）：At most once，至多一次，消息可能丢失，但绝不会重复传输；At least once，至少一次，消息绝不会丢，但是可能会重复；Exactly once，精确一次，每条消息肯定会被传输一次且仅一次。对于大多数消息中间件而言，一般只提供At most once和At least once两种传输保障，对于第三种一般很难做到，由此消息幂等性也很难保证。

Kafka自0.11版本开始引入了幂等性和事务，Kafka的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，这两个功能加起来可以让Kafka具备EOS（Exactly Once Semantic）的能力。

不过如果要考虑全局的幂等，还需要与从上下游方面综合考虑，即关联业务层面，幂等处理本身也是业务层面所需要考虑的重要议题。以下游消费者层面为例，有可能消费者消费完一条消息之后没有来得及确认消息就发生异常，等到恢复之后又得重新消费原来消费过的那条消息，那么这种类型的消息幂等是无法有消息中间件层面来保证的。如果要保证全局的幂等，需要引入更多的外部资源来保证，比如以订单号作为唯一性标识，并且在下游设置一个去重表

事务性消息
Kafka 与 RabbitMQ 都支持
事务本身是一个并不陌生的词汇，事务是由事务开始（Begin Transaction）和事务结束（End Transaction）之间执行的全体操作组成。支持事务的消息中间件并不在少数，Kafka和RabbitMQ都支持，不过此两者的事务是指生产者发生消息的事务，要么发送成功，要么发送失败。消息中间件可以作为用来实现分布式事务的一种手段，但其本身并不提供全局分布式事务的功能


性能
Kafka在开启幂等、事务功能的时候会使其性能降低，RabbitMQ在开启rabbitmq_tracing插件的时候也会极大的影响其性能。消息中间件的性能一般是指其吞吐量，虽然从功能维度上来说，RabbitMQ的优势要大于Kafka，但是Kafka的吞吐量要比RabbitMQ高出1至2个数量级，一般RabbitMQ的单机QPS在万级别之内，而Kafka的单机QPS可以维持在十万级别，甚至可以达到百万级。

消息中间件的吞吐量始终会受到硬件层面的限制。就以网卡带宽为例，如果单机单网卡的带宽为1Gbps，如果要达到百万级的吞吐，那么消息体大小不得超过(1Gb/8)/100W，即约等于134B，换句话说如果消息体大小超过134B，那么就不可能达到百万级别的吞吐。这种计算方式同样可以适用于内存和磁盘。


可靠性+可用性
消息中间件的可靠性是指对消息不丢失的保障程度；而消息中间件的可用性是指无故障运行的时间百分比，通常用几个9来衡量。

就目前而言，在金融支付领域使用RabbitMQ居多，而在日志处理、大数据等方面Kafka使用居多

对于RabbitMQ而言，最正统的监控管理工具莫过于rabbitmq_management插件



1. 消息先从生产者Producer出发到达交换器Exchange；
2. 交换器Exchange根据路由规则将消息转发对应的队列Queue之上；
3. 消息在队列Queue上进行存储；
4. 消费者Consumer订阅队列Queue并进行消费

RabbitMQ 事务机制
channel.txSelect 用于将当前的信道设置成事务模式
channel.txCommit 用于提交事务
channel.txRollback 用于事务回滚

使用事务会影响 RabbitMQ 的性能，可以通过发送方确认机制（publisher confirm）进行改进

生产者将信道设置成confirm（确认）模式
在确认模式的信道发布的消息会被指派一个唯一的 ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一ID），这就使得生产者知晓消息已经正确到达了目的地
RabbitMQ回传给生产者的确认消息中的deliveryTag包含了确认消息的序号，此外RabbitMQ也可以设置channel.basicAck方法中的multiple参数，表示到这个序号之前的所有消息都已经得到了处理

事务机制在一条消息发送之后会使发送端阻塞，以等待RabbitMQ的回应，之后才能继续发送下一条消息
发送方确认机制最大的好处在于它是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack（Basic.Nack）命令，生产者应用程序同样可以在回调方法中处理该nack命令

生产者通过调用channel.confirmSelect方法（即Confirm.Select命令）将信道设置为confirm模式，之后RabbitMQ会返回 Confirm.Select-Ok命令表示同意生产者将当前信道设置为confirm模式

事务机制和publisher confirm机制两者是互斥的，不能共存

事务机制和publisher confirm机制确保的是消息能够正确的发送至RabbitMQ，这里的“发送至RabbitMQ”的含义是指消息被正确的发往至RabbitMQ的交换器，如果此交换器没有匹配的队列的话，那么消息也将会丢失。

当mandatory参数设为true时，交换器无法根据自身的类型和路由键找到一个符合条件的队列的话，那么RabbitMQ会调用Basic.Return命令将消息返回给生产者。当mandatory参数设置为false时，出现上述情形的话，消息直接被丢弃

若生产者没有成功将消息路由到队列，此时 RabbitMQ 会通过 Basic.Return 返回 "mandatory test"，之后生产者客户端通过 ReturnListener 监听到这个事件
```
channel.basicPublish(EXCHANGE_NAME, "", true, MessageProperties.PERSISTENT_TEXT_PLAIN, "mandatory test".getBytes());
channel.addReturnListener(new ReturnListener() {
   public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP
           .BasicProperties basicProperties, byte[] body) throws IOException {
       String message = new String(body);
       System.out.println("Basic.Return返回的结果是：" + message);
   }
});
```
生产者可以通过ReturnListener中返回的消息来重新投递或者其它方案来提高消息的可靠性

如果不设置 mandatory，可使用备份交换器，用于将未被路由的消息存储在 RabbitMQ 中
。可以通过在声明交换器（调用channel.exchangeDeclare方法）的时候添加alternate-exchange参数来实现，也可以通过策略的方式实现。如果两者同时使用的话，前者的优先级更高，会覆盖掉Policy的设置。建议将备份交换器设置为 fanout 类型。如果备份交换器和mandatory参数一起使用，那么mandatory参数无效


消息存入队列之后的可靠性
1. 队列持久化：队列的持久化是通过在声明队列时将durable参数置为true实现的，如果队列不设置持久化，那么在RabbitMQ服务重启之后，相关队列的元数据将会丢失，此时数据也会丢失
2. 消息持久化：通过将消息的投递模式（BasicProperties中的deliveryMode属性）设置为2即可实现消息的持久化

在持久化的消息正确存入RabbitMQ之后，还需要有一段时间（虽然很短，但是不可忽视）才能存入磁盘之中。RabbitMQ并不会为每条消息都做同步存盘（调用内核的fsync6方法）的处理，可能仅仅保存到操作系统缓存之中而不是物理磁盘之中。如果在这段时间内RabbitMQ服务节点发生了宕机、重启等异常情况，消息保存还没来得及落盘，那么这些消息将会丢失。如果在Phase1中采用了事务机制或者publisher confirm机制的话，服务端的返回是在消息落盘之后执行的，这样可以进一步的提高了消息的可靠性。但是即便如此也无法避免单机故障且无法修复（比如磁盘损毁）而引起的消息丢失，这里就需要引入镜像队列。镜像队列相当于配置了副本，绝大多数分布式的东西都有多副本的概念来确保HA。在镜像队列中，如果主节点（master）在此特殊时间内挂掉，可以自动切换到从节点（slave），这样有效的保证了高可用性

保证消息从队列可靠地达到消费者
RabbitMQ提供了消息确认机制（message acknowledgement）。消费者在订阅队列时，可以指定autoAck参数，当autoAck等于false时，RabbitMQ会等待消费者显式地回复确认信号后才从内存（或者磁盘）中移去消息（实质上是先打上删除标记，之后再删除）。当autoAck等于true时，RabbitMQ会自动把发送出去的消息置为确认，然后从内存（或者磁盘）中删除，而不管消费者是否真正的消费到了这些消息

当autoAck参数置为false，对于RabbitMQ服务端而言，队列中的消息分成了两个部分：一部分是等待投递给消费者的消息；一部分是已经投递给消费者，但是还没有收到消费者确认信号的消息。如果RabbitMQ一直没有收到消费者的确认信号，并且消费此消息的消费者已经断开连接，则RabbitMQ会安排该消息重新进入队列，等待投递给下一个消费者，当然也有可能还是原来的那个消费者。
RabbitMQ不会为未确认的消息设置过期时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开

如果消息消费失败，也可以调用Basic.Reject或者Basic.Nack来拒绝当前消息而不是确认，如果只是简单的拒绝那么消息会丢失，需要将相应的requeue参数设置为true，那么RabbitMQ会重新将这条消息存入队列，以便可以发送给下一个订阅的消费者。如果requeue参数设置为false的话，RabbitMQ立即会把消息从队列中移除，而不会把它发送给新的消费者。
还有一种情况需要考虑：requeue的消息是存入队列头部的，即可以快速的又被发送给消费，如果此时消费者又不能正确的消费而又requeue的话就会进入一个无尽的循环之中。对于这种情况，笔者的建议是在出现无法正确消费的消息时不要采用requeue的方式来确保消息可靠性，而是重新投递到新的队列中，比如设定的死信队列中，以此可以避免前面所说的死循环而又可以确保相应的消息不丢失。对于死信队列中的消息可以用另外的方式来消费分析，以便找出问题的根本。


Rabbit管理
执行 rabbitmq-plugins enable rabbitmq_management命令，开启Web管理插件
打开浏览器并访问： http://localhost:15672/，并使用默认用户 guest登录，密码也为 guest


Message消息由消息头和消息体组成，消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等
Exchange交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列
Binding绑定，基于路由键将交换器和消息队列连接起来的路由规则


消息队列作用
解耦、异步、削峰


RabbitMQ提供transaction和confirm模式来确保生产者不丢消息
transaction机制
发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。缺点就是吞吐量下降

confirm机制
channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，可以进行重试操作

消息队列丢数据
开启持久化磁盘的配置，和confirm机制配合使用，可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发

消息持久化：
将queue的持久化标识durable设置为true,则代表是一个持久的队列
发送消息的时候将deliveryMode=2

消费者丢数据
消费者丢数据一般是因为采用了自动确认消息模式，应采用手动确认消息

消息的顺序性
将需要保持先后顺序的消息放到同一个消息队列中，只用一个消费者去消费该队列
有多个消费者去消费则采取重试策略
